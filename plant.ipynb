{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":75676,"sourceType":"datasetVersion","datasetId":42780},{"sourceId":182633,"sourceType":"datasetVersion","datasetId":78313}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# kütüphaneler\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt  \nimport seaborn as sns            \nimport os                        \n\nimport torch\nimport torch.nn as nn            \nimport torch.optim as optim      \n\nimport torchvision\nfrom torchvision import datasets, models, transforms \n\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nfrom PIL import Image\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Kullanılan Cihaz: {device}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-17T11:49:36.005687Z","iopub.execute_input":"2025-12-17T11:49:36.005990Z","iopub.status.idle":"2025-12-17T11:49:46.089704Z","shell.execute_reply.started":"2025-12-17T11:49:36.005964Z","shell.execute_reply":"2025-12-17T11:49:46.088998Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# data preprocessing\nimport torch\nimport os\nfrom torchvision import transforms, datasets\nfrom torch.utils.data import DataLoader, Subset, Dataset, ConcatDataset\n\n# Resnet renk standardı\nmean_nums = [0.485, 0.456, 0.406]\nstd_nums = [0.229, 0.224, 0.225]\n# veriyi modele vermek üzere 2 ye böldük train yani eğitileceği data ve val yani test edileceği data\n# train kısmındaki fotoğraflara çevirme, döndürme, ışık ayarlarını değiştirme gibi değişiklikler uygulayarak modelin\n# ezberlemesini zorlaştırıyoruz\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(30),\n        transforms.ColorJitter(brightness= 0.2, contrast= 0.2),\n        transforms.ToTensor(),\n        transforms.Normalize(mean_nums, std_nums)\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean_nums, std_nums)\n    ]),\n}\n\nbase_dir = '/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)'\ntrain_dir = os.path.join(base_dir, 'train')\nvalid_dir = os.path.join(base_dir, 'valid')\n\nhedef_bitkiler = [\"Tomato\", \"Apple\", \"Grape\", \"Corn\"]\n\n# datasetteki tüm verileri kullanmadığımız için veriyi alırken etikette sıkıntı çıkıyordu onun için yardımcı \nclass RemappedSubset(Dataset):\n    def __init__(self, subset, old_to_new_mapping):\n        self.subset = subset\n        self.mapping = old_to_new_mapping\n    \n    def __len__(self):\n        return len(self.subset)\n    \n    def __getitem__(self, idx):\n        image, old_label = self.subset[idx]\n        new_label = self.mapping[old_label]\n        return image, new_label\n\nclass NaturalImagesDataset(Dataset):\n    def __init__(self, root_dir, transform, label_idx, limit=600):\n\n        full_dataset = datasets.ImageFolder(root=root_dir, transform=transform)\n        \n        total_images = len(full_dataset)\n\n        actual_limit = min(limit, total_images)\n\n        indices = torch.randperm(total_images)[:actual_limit]\n\n        self.dataset = Subset(full_dataset, indices)\n        self.label_idx = label_idx\n        \n    def __len__(self):\n        return len(self.dataset)\n    \n    def __getitem__(self, idx):\n        # Subset içinden resmi al\n        image, _ = self.dataset[idx] \n        # Orijinal etiketi (_) çöpe at, bizim 'Others' etiketini ver\n        return image, self.label_idx\n\ndef filtrele_ve_olustur(ana_klasor_yolu, transform_tipi):\n    full_dataset = datasets.ImageFolder(\n        root=ana_klasor_yolu,\n        transform=data_transforms[transform_tipi]\n    )\n    \n    # Hedef sınıfların eski indekslerini bul\n    hedef_sinif_indeksleri = []\n    for i, sinif_adi in enumerate(full_dataset.classes):\n        for bitki in hedef_bitkiler:\n            if bitki in sinif_adi:\n                hedef_sinif_indeksleri.append(i)\n                break \n    \n    # Bu sınıflara ait resimlerin indekslerini topla\n    secilen_resim_indeksleri = [i for i, label in enumerate(full_dataset.targets) \n                                if label in hedef_sinif_indeksleri]\n    \n    # Subset oluştur\n    subset_dataset = Subset(full_dataset, secilen_resim_indeksleri)\n    \n    # Etiketleri düzenliyoruz(0,1,2...)\n    hedef_sinif_indeksleri_sorted = sorted(hedef_sinif_indeksleri)\n    old_to_new = {old_idx: new_idx for new_idx, old_idx in enumerate(hedef_sinif_indeksleri_sorted)}\n    \n    # Remapped dataset oluştur\n    remapped_dataset = RemappedSubset(subset_dataset, old_to_new)\n    \n    # Seçilen sınıf isimlerini de döndür\n    secilen_sinif_isimleri = [full_dataset.classes[i] for i in hedef_sinif_indeksleri_sorted]\n    \n    return remapped_dataset, secilen_sinif_isimleri\n\n# Eğitim seti (Train klasöründen)\ntrain_set_plants, bitki_siniflari = filtrele_ve_olustur(train_dir, 'train')\n\n# Test seti (Valid klasöründen)\nval_set_plants, _ = filtrele_ve_olustur(valid_dir, 'val')\n\nothers_label_idx = len(bitki_siniflari)\n\nnatural_img_path = '/kaggle/input/natural-images/natural_images' \n\n# Train için \nnatural_train = NaturalImagesDataset(\n    root_dir=natural_img_path, \n    transform=data_transforms['train'], \n    label_idx=others_label_idx, \n    limit=600\n)\n\n# Valid için \nnatural_val = NaturalImagesDataset(\n    root_dir=natural_img_path, \n    transform=data_transforms['val'], \n    label_idx=others_label_idx, \n    limit=150\n)\n\n# Bitki verisi ile Natural Images verisini birleştir\ntrain_set = ConcatDataset([train_set_plants, natural_train])\nval_set = ConcatDataset([val_set_plants, natural_val])\n\n# Sınıf listesine Others'ı ekle\nbitki_siniflari.append(\"Others\")\n# ---------------------------------------------\n\n# DataLoader oluştur\ntrain_loader = DataLoader(train_set, batch_size=32, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_set, batch_size=32, shuffle=False, num_workers=2)\n\n# Bilgi yazdır\nprint(\"-\" * 50)\nprint(f\"Toplam Eğitim Resmi: {len(train_set)}\")\nprint(f\"Toplam Test Resmi:   {len(val_set)}\")\nprint(f\"Tespit Edilecek Sınıf Sayısı: {len(bitki_siniflari)}\")\nprint(\"-\" * 50)\nprint(\"Seçilen Sınıflar:\")\nfor i, s in enumerate(bitki_siniflari):\n    print(f\" [{i}] {s}\")\nprint(\"-\" * 50)\n\n# Etiketlerin doğru olduğunu doğrula\nimages, labels = next(iter(train_loader))\nprint(f\"Etiket Kontrolü:\")\nprint(f\"   Min etiket: {labels.min().item()}\")\nprint(f\"   Max etiket: {labels.max().item()}\")\nprint(f\"   Benzersiz etiketler: {sorted(labels.unique().tolist())}\")\nprint(f\"   Beklenen aralık: 0-{len(bitki_siniflari)-1}\")\nprint(\"-\" * 50)\n\n# Model için sınıf sayısı\nnum_classes = len(bitki_siniflari)","metadata":{"execution":{"iopub.status.busy":"2025-12-17T11:49:46.090830Z","iopub.execute_input":"2025-12-17T11:49:46.091198Z","iopub.status.idle":"2025-12-17T11:51:30.617970Z","shell.execute_reply.started":"2025-12-17T11:49:46.091178Z","shell.execute_reply":"2025-12-17T11:51:30.617048Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Model inşası\nimport torch.nn as nn\nfrom torchvision.models import ResNet50_Weights\n\nnum_classes = len(bitki_siniflari)\n\n# 1. Modeli İndir\nmodel = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n\n# 2. Son katman değişimi\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, num_classes)\n\n# 3. GPU'ya Gönder\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T11:51:30.619160Z","iopub.execute_input":"2025-12-17T11:51:30.619447Z","iopub.status.idle":"2025-12-17T11:51:31.966004Z","shell.execute_reply.started":"2025-12-17T11:51:30.619396Z","shell.execute_reply":"2025-12-17T11:51:31.965385Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Eğitim\nimport torch.optim as optim\nimport time\n\nimages, labels = next(iter(train_loader))\nassert labels.min() >= 0, f\"Negatif etiket: {labels.min()}\"\nassert labels.max() < model.fc.out_features, f\"Etiket {labels.max()} çok büyük! Model {model.fc.out_features} sınıf bekliyor.\"\nprint(\"Etiketler doğru!\")\n\n# Hata Hesaplayıcı: Sınıflandırma olduğu için CrossEntropy kullanıyoruz.\ncriterion = nn.CrossEntropyLoss()\n\n# Optimizer (Güncelleyici): Modelin her adımda ne kadar güncelleme yapacağı(kendini düzelteceği)\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n# Eğitim fonksiyonu\ndef train_model(model, criterion, optimizer, num_epochs=10):\n    start_time = time.time()\n    train_losses = [] # Grafik çizmek için hatayı sakla\n    \n    print(f\"Toplam {num_epochs} tur atılacak.\")\n    \n    for epoch in range(num_epochs):\n        model.train() # Modeli antrenman moduna al\n        running_loss = 0.0\n        correct = 0\n        total = 0\n        \n        # Veriyi çekiyoruz\n        for i, (inputs, labels) in enumerate(train_loader):\n            inputs, labels = inputs.to(device), labels.to(device)\n            \n            # Sıfırla\n            optimizer.zero_grad()\n            \n            # Model tahmin etsin\n            outputs = model(inputs)\n            \n            # Güncellemek üzere loss u hesapla\n            loss = criterion(outputs, labels)\n            \n            # Geriye bak\n            loss.backward()\n            \n            # Güncelle (öğrenme kısmı)\n            optimizer.step()\n            \n            # İstatistik\n            running_loss += loss.item() * inputs.size(0)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n        # Her epoch sonunda rapor\n        epoch_loss = running_loss / len(train_set)\n        epoch_acc = 100 * correct / total\n        train_losses.append(epoch_loss)\n        \n        print(f\"Tur [{epoch+1}/{num_epochs}] Bitti -> Hata: {epoch_loss:.4f} | Başarı: %{epoch_acc:.2f}\")\n\n    end_time = time.time() - start_time\n    print(f\"Eğitim Tamamlandı! Süre: {end_time // 60:.0f}dk {end_time % 60:.0f}sn\")\n    return train_losses\n\n# Eğitimi başlat\nloss_history = train_model(model, criterion, optimizer, num_epochs=10)\n\n# Kaydet\ntorch.save(model.state_dict(), 'model_with_natural_images.pth')\nprint(\"Model dosyası kaydedildi: model_with_natural_images.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T11:51:31.967379Z","iopub.execute_input":"2025-12-17T11:51:31.967670Z","iopub.status.idle":"2025-12-17T13:12:28.280384Z","shell.execute_reply.started":"2025-12-17T11:51:31.967648Z","shell.execute_reply":"2025-12-17T13:12:28.279360Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Değerlendirme ve Raporlama\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\nimport torch\nimport glob\nimport random\nfrom PIL import Image\nimport os\n\nplt.figure(figsize=(10, 5))\nplt.plot(loss_history, label='Eğitim Hatası (Training Loss)')\nplt.title('Modelin Öğrenme Grafiği')\nplt.xlabel('Epoch Sayısı')\nplt.ylabel('Hata Değeri')\nplt.legend()\nplt.grid(True)\nplt.show()\n\nprint(\"Model test ediliyor, lütfen bekleyin...\")\ntum_tahminler = []\ntum_gercekler = []\n\nmodel.eval() \nwith torch.no_grad():\n    for inputs, labels in val_loader:\n        inputs = inputs.to(device)\n        outputs = model(inputs)\n        _, preds = torch.max(outputs, 1)\n        \n        tum_tahminler.extend(preds.cpu().numpy())\n        tum_gercekler.extend(labels.numpy())\n\ntry:\n    target_names = bitki_siniflari\nexcept:\n    target_names = full_dataset.classes\n\nprint(\"\\n--- DETAYLI SINIFLANDIRMA RAPORU ---\")\nprint(classification_report(tum_gercekler, tum_tahminler, target_names=target_names))\n\ncm = confusion_matrix(tum_gercekler, tum_tahminler)\n\nplt.figure(figsize=(12, 10))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=target_names, \n            yticklabels=target_names)\nplt.xlabel('Modelin Tahmini')\nplt.ylabel('Gerçek Durum')\nplt.title('Confusion Matrix (Hata Haritası)')\nplt.xticks(rotation=90) \nplt.show()\n\n# --- 1. SINIF DAĞILIMI GRAFİĞİ (Bar Chart) ---\nprint(\"Veri seti dağılımı hesaplanıyor (Biraz sürebilir)...\")\n\n# DataLoader'dan gerçek sayıları al (En garantisi budur)\nlabel_counts = torch.zeros(len(bitki_siniflari))\nwith torch.no_grad():\n    for _, targets in train_loader:\n        for target in targets:\n            label_counts[target] += 1\n\ncounts_np = label_counts.numpy().astype(int)\n\n# Grafiği Çiz\nplt.figure(figsize=(14, 6))\nax = sns.barplot(x=bitki_siniflari, y=counts_np, palette=\"viridis\")\n\n# Sayıları çubukların üstüne yaz\nfor i, v in enumerate(counts_np):\n    ax.text(i, v + 5, str(v), color='black', fontweight='bold', ha='center', fontsize=9)\n\nplt.title('Eğitim Veri Seti Sınıf Dağılımı (Bitkiler + Others)', fontsize=15)\nplt.ylabel('Fotoğraf Sayısı')\nplt.xticks(rotation=90) # İsimler sığsın diye dik yaptık\nplt.grid(axis='y', linestyle='--', alpha=0.5)\nplt.tight_layout()\nplt.show()\n\n# --- 2. ÖRNEK FOTOĞRAFLAR (Bitkiler + Others) ---\n# Göstermek istediğimiz bitkiler\nvisual_targets = [\"Tomato\", \"Apple\", \"Grape\", \"Corn\"]\n\n# Tablo boyutunu ayarlıyoruz (Satır sayısı = Bitkiler + Others için 1 satır)\nfig, axes = plt.subplots(len(visual_targets) + 1, 2, figsize=(10, 18))\nfig.suptitle('Veri Setinden Rastgele Örnekler', fontsize=16)\n\n# A) BİTKİLERİ GÖSTER (Sağlıklı vs Hasta)\nfor i, plant in enumerate(visual_targets):\n    # Klasör desenleri (Attığın fotodaki yapıya uygun)\n    # Örn: .../train/Apple___healthy\n    healthy_pattern = os.path.join(train_dir, f\"{plant}*healthy*\")\n    disease_pattern = os.path.join(train_dir, f\"{plant}*\")\n    \n    # Klasörleri bul\n    healthy_folders = glob.glob(healthy_pattern)\n    all_folders = glob.glob(disease_pattern)\n    disease_folders = [f for f in all_folders if \"healthy\" not in f]\n    \n    # 1. Sağlıklı Resim (Sol Sütun)\n    if healthy_folders:\n        # Klasörün içindeki jpg'leri bul\n        img_files = glob.glob(os.path.join(healthy_folders[0], \"*\"))\n        if img_files:\n            img = Image.open(random.choice(img_files))\n            axes[i, 0].imshow(img)\n            axes[i, 0].set_title(f\"{plant} - Sağlıklı\")\n    axes[i, 0].axis('off')\n\n    # 2. Hastalıklı Resim (Sağ Sütun)\n    if disease_folders:\n        random_disease_folder = random.choice(disease_folders)\n        disease_name = os.path.basename(random_disease_folder).split(\"___\")[-1].replace(\"_\", \" \")\n        \n        img_files = glob.glob(os.path.join(random_disease_folder, \"*\"))\n        if img_files:\n            img = Image.open(random.choice(img_files))\n            axes[i, 1].imshow(img)\n            axes[i, 1].set_title(f\"{plant} - {disease_name}\")\n    axes[i, 1].axis('off')\n\n# B) OTHERS (Alakasız Nesneler) GÖSTER\n# En alt satıra Others örnekleri koyalım\nrow_idx = len(visual_targets)\n\n# Natural Images klasöründen rastgele iki sınıf seç (Örn: Car, Person)\nif os.path.exists(natural_img_path):\n    others_categories = os.listdir(natural_img_path) # [airplane, car, cat...]\n    \n    # Sol Sütun (Rastgele Others 1)\n    cat1 = random.choice(others_categories)\n    img_files1 = glob.glob(os.path.join(natural_img_path, cat1, \"*\"))\n    if img_files1:\n        img = Image.open(random.choice(img_files1))\n        axes[row_idx, 0].imshow(img)\n        axes[row_idx, 0].set_title(f\"Others (Örn: {cat1})\")\n    \n    # Sağ Sütun (Rastgele Others 2)\n    cat2 = random.choice(others_categories)\n    img_files2 = glob.glob(os.path.join(natural_img_path, cat2, \"*\"))\n    if img_files2:\n        img = Image.open(random.choice(img_files2))\n        axes[row_idx, 1].imshow(img)\n        axes[row_idx, 1].set_title(f\"Others (Örn: {cat2})\")\n\naxes[row_idx, 0].axis('off')\naxes[row_idx, 1].axis('off')\n\nplt.tight_layout()\nplt.subplots_adjust(top=0.93)\nplt.show()\n\n# Mevcut 'cm' (Confusion Matrix) değişkenini kullanır.\n\n# Köşegen elemanları (doğru tahminler) / Toplam satır sayısı (gerçek adet)\nclass_accuracy = cm.diagonal() / cm.sum(axis=1)\n\nplt.figure(figsize=(12, 6))\n# Renk paleti\ncolors = sns.color_palette(\"husl\", len(bitki_siniflari))\nbars = plt.bar(bitki_siniflari, class_accuracy, color=colors)\n\nplt.title('Sınıf Bazlı Doğruluk Oranları (Per-Class Accuracy)', fontsize=15)\nplt.ylabel('Başarı Oranı (0.0 - 1.0)', fontsize=12)\nplt.xlabel('Sınıflar', fontsize=12)\nplt.xticks(rotation=45)\nplt.ylim(0, 1.1) \n\n# Çubukların üzerine yüzdeleri yaz\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n             f'%{height*100:.1f}',\n             ha='center', va='bottom', fontweight='bold')\n\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n\n# Matrisi yüzdelik hale getir (Her satırı kendi toplamına böl)\ncm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\nplt.figure(figsize=(12, 10))\nsns.heatmap(cm_normalized, annot=True, fmt='.1%', cmap='Blues', vmin=0, vmax=1,\n            xticklabels=bitki_siniflari, \n            yticklabels=bitki_siniflari)\nplt.xlabel('Modelin Tahmini', fontsize=12)\nplt.ylabel('Gerçek Durum', fontsize=12)\nplt.title('Normalize Edilmiş Confusion Matrix (Yüzdelik Başarı)', fontsize=15)\nplt.xticks(rotation=90) \nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T13:12:28.281626Z","iopub.execute_input":"2025-12-17T13:12:28.281943Z","iopub.status.idle":"2025-12-17T13:15:25.014855Z","shell.execute_reply.started":"2025-12-17T13:12:28.281906Z","shell.execute_reply":"2025-12-17T13:15:25.013916Z"}},"outputs":[],"execution_count":null}]}