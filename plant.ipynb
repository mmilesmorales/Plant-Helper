{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-17T11:49:36.005990Z",
     "iopub.status.busy": "2025-12-17T11:49:36.005687Z",
     "iopub.status.idle": "2025-12-17T11:49:46.089704Z",
     "shell.execute_reply": "2025-12-17T11:49:46.088998Z",
     "shell.execute_reply.started": "2025-12-17T11:49:36.005964Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# kütüphaneler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns            \n",
    "import os                        \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn            \n",
    "import torch.optim as optim      \n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms \n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Kullanılan Cihaz: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T11:49:46.091198Z",
     "iopub.status.busy": "2025-12-17T11:49:46.090830Z",
     "iopub.status.idle": "2025-12-17T11:51:30.617970Z",
     "shell.execute_reply": "2025-12-17T11:51:30.617048Z",
     "shell.execute_reply.started": "2025-12-17T11:49:46.091178Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "import torch\n",
    "import os\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Subset, Dataset, ConcatDataset\n",
    "\n",
    "# Resnet renk standardı\n",
    "mean_nums = [0.485, 0.456, 0.406]\n",
    "std_nums = [0.229, 0.224, 0.225]\n",
    "# veriyi modele vermek üzere 2 ye böldük train yani eğitileceği data ve val yani test edileceği data\n",
    "# train kısmındaki fotoğraflara çevirme, döndürme, ışık ayarlarını değiştirme gibi değişiklikler uygulayarak modelin\n",
    "# ezberlemesini zorlaştırıyoruz\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.ColorJitter(brightness= 0.2, contrast= 0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean_nums, std_nums)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean_nums, std_nums)\n",
    "    ]),\n",
    "}\n",
    "\n",
    "base_dir = '/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "valid_dir = os.path.join(base_dir, 'valid')\n",
    "\n",
    "hedef_bitkiler = [\"Tomato\", \"Apple\", \"Grape\", \"Corn\"]\n",
    "\n",
    "# datasetteki tüm verileri kullanmadığımız için veriyi alırken etikette sıkıntı çıkıyordu onun için yardımcı \n",
    "class RemappedSubset(Dataset):\n",
    "    def __init__(self, subset, old_to_new_mapping):\n",
    "        self.subset = subset\n",
    "        self.mapping = old_to_new_mapping\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image, old_label = self.subset[idx]\n",
    "        new_label = self.mapping[old_label]\n",
    "        return image, new_label\n",
    "\n",
    "class NaturalImagesDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform, label_idx, limit=600):\n",
    "\n",
    "        full_dataset = datasets.ImageFolder(root=root_dir, transform=transform)\n",
    "        \n",
    "        total_images = len(full_dataset)\n",
    "\n",
    "        actual_limit = min(limit, total_images)\n",
    "\n",
    "        indices = torch.randperm(total_images)[:actual_limit]\n",
    "\n",
    "        self.dataset = Subset(full_dataset, indices)\n",
    "        self.label_idx = label_idx\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Subset içinden resmi al\n",
    "        image, _ = self.dataset[idx] \n",
    "        # Orijinal etiketi (_) çöpe at, bizim 'Others' etiketini ver\n",
    "        return image, self.label_idx\n",
    "\n",
    "def filtrele_ve_olustur(ana_klasor_yolu, transform_tipi):\n",
    "    full_dataset = datasets.ImageFolder(\n",
    "        root=ana_klasor_yolu,\n",
    "        transform=data_transforms[transform_tipi]\n",
    "    )\n",
    "    \n",
    "    # Hedef sınıfların eski indekslerini bul\n",
    "    hedef_sinif_indeksleri = []\n",
    "    for i, sinif_adi in enumerate(full_dataset.classes):\n",
    "        for bitki in hedef_bitkiler:\n",
    "            if bitki in sinif_adi:\n",
    "                hedef_sinif_indeksleri.append(i)\n",
    "                break \n",
    "    \n",
    "    # Bu sınıflara ait resimlerin indekslerini topla\n",
    "    secilen_resim_indeksleri = [i for i, label in enumerate(full_dataset.targets) \n",
    "                                if label in hedef_sinif_indeksleri]\n",
    "    \n",
    "    # Subset oluştur\n",
    "    subset_dataset = Subset(full_dataset, secilen_resim_indeksleri)\n",
    "    \n",
    "    # Etiketleri düzenliyoruz(0,1,2...)\n",
    "    hedef_sinif_indeksleri_sorted = sorted(hedef_sinif_indeksleri)\n",
    "    old_to_new = {old_idx: new_idx for new_idx, old_idx in enumerate(hedef_sinif_indeksleri_sorted)}\n",
    "    \n",
    "    # Remapped dataset oluştur\n",
    "    remapped_dataset = RemappedSubset(subset_dataset, old_to_new)\n",
    "    \n",
    "    # Seçilen sınıf isimlerini de döndür\n",
    "    secilen_sinif_isimleri = [full_dataset.classes[i] for i in hedef_sinif_indeksleri_sorted]\n",
    "    \n",
    "    return remapped_dataset, secilen_sinif_isimleri\n",
    "\n",
    "# Eğitim seti (Train klasöründen)\n",
    "train_set_plants, bitki_siniflari = filtrele_ve_olustur(train_dir, 'train')\n",
    "\n",
    "# Test seti (Valid klasöründen)\n",
    "val_set_plants, _ = filtrele_ve_olustur(valid_dir, 'val')\n",
    "\n",
    "others_label_idx = len(bitki_siniflari)\n",
    "\n",
    "natural_img_path = '/kaggle/input/natural-images/natural_images' \n",
    "\n",
    "# Train için \n",
    "natural_train = NaturalImagesDataset(\n",
    "    root_dir=natural_img_path, \n",
    "    transform=data_transforms['train'], \n",
    "    label_idx=others_label_idx, \n",
    "    limit=600\n",
    ")\n",
    "\n",
    "# Valid için \n",
    "natural_val = NaturalImagesDataset(\n",
    "    root_dir=natural_img_path, \n",
    "    transform=data_transforms['val'], \n",
    "    label_idx=others_label_idx, \n",
    "    limit=150\n",
    ")\n",
    "\n",
    "# Bitki verisi ile Natural Images verisini birleştir\n",
    "train_set = ConcatDataset([train_set_plants, natural_train])\n",
    "val_set = ConcatDataset([val_set_plants, natural_val])\n",
    "\n",
    "# Sınıf listesine Others'ı ekle\n",
    "bitki_siniflari.append(\"Others\")\n",
    "# ---------------------------------------------\n",
    "\n",
    "# DataLoader oluştur\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "# Bilgi yazdır\n",
    "print(\"-\" * 50)\n",
    "print(f\"Toplam Eğitim Resmi: {len(train_set)}\")\n",
    "print(f\"Toplam Test Resmi:   {len(val_set)}\")\n",
    "print(f\"Tespit Edilecek Sınıf Sayısı: {len(bitki_siniflari)}\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Seçilen Sınıflar:\")\n",
    "for i, s in enumerate(bitki_siniflari):\n",
    "    print(f\" [{i}] {s}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Etiketlerin doğru olduğunu doğrula\n",
    "images, labels = next(iter(train_loader))\n",
    "print(f\"Etiket Kontrolü:\")\n",
    "print(f\"   Min etiket: {labels.min().item()}\")\n",
    "print(f\"   Max etiket: {labels.max().item()}\")\n",
    "print(f\"   Benzersiz etiketler: {sorted(labels.unique().tolist())}\")\n",
    "print(f\"   Beklenen aralık: 0-{len(bitki_siniflari)-1}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Model için sınıf sayısı\n",
    "num_classes = len(bitki_siniflari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T11:51:30.619447Z",
     "iopub.status.busy": "2025-12-17T11:51:30.619160Z",
     "iopub.status.idle": "2025-12-17T11:51:31.966004Z",
     "shell.execute_reply": "2025-12-17T11:51:31.965385Z",
     "shell.execute_reply.started": "2025-12-17T11:51:30.619396Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Model inşası\n",
    "import torch.nn as nn\n",
    "from torchvision.models import ResNet50_Weights\n",
    "\n",
    "num_classes = len(bitki_siniflari)\n",
    "\n",
    "# 1. Modeli İndir\n",
    "model = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "# 2. Son katman değişimi\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "# 3. GPU'ya Gönder\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T11:51:31.967670Z",
     "iopub.status.busy": "2025-12-17T11:51:31.967379Z",
     "iopub.status.idle": "2025-12-17T13:12:28.280384Z",
     "shell.execute_reply": "2025-12-17T13:12:28.279360Z",
     "shell.execute_reply.started": "2025-12-17T11:51:31.967648Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Eğitim\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "assert labels.min() >= 0, f\"Negatif etiket: {labels.min()}\"\n",
    "assert labels.max() < model.fc.out_features, f\"Etiket {labels.max()} çok büyük! Model {model.fc.out_features} sınıf bekliyor.\"\n",
    "print(\"Etiketler doğru!\")\n",
    "\n",
    "# Hata Hesaplayıcı: Sınıflandırma olduğu için CrossEntropy kullanıyoruz.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer (Güncelleyici): Modelin her adımda ne kadar güncelleme yapacağı(kendini düzelteceği)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Eğitim fonksiyonu\n",
    "def train_model(model, criterion, optimizer, num_epochs=10):\n",
    "    start_time = time.time()\n",
    "    train_losses = [] # Grafik çizmek için hatayı sakla\n",
    "    \n",
    "    print(f\"Toplam {num_epochs} tur atılacak.\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Modeli antrenman moduna al\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        # Veriyi çekiyoruz\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Sıfırla\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Model tahmin etsin\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Güncellemek üzere loss u hesapla\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Geriye bak\n",
    "            loss.backward()\n",
    "            \n",
    "            # Güncelle (öğrenme kısmı)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # İstatistik\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "        # Her epoch sonunda rapor\n",
    "        epoch_loss = running_loss / len(train_set)\n",
    "        epoch_acc = 100 * correct / total\n",
    "        train_losses.append(epoch_loss)\n",
    "        \n",
    "        print(f\"Tur [{epoch+1}/{num_epochs}] Bitti -> Hata: {epoch_loss:.4f} | Başarı: %{epoch_acc:.2f}\")\n",
    "\n",
    "    end_time = time.time() - start_time\n",
    "    print(f\"Eğitim Tamamlandı! Süre: {end_time // 60:.0f}dk {end_time % 60:.0f}sn\")\n",
    "    return train_losses\n",
    "\n",
    "# Eğitimi başlat\n",
    "loss_history = train_model(model, criterion, optimizer, num_epochs=10)\n",
    "\n",
    "# Kaydet\n",
    "torch.save(model.state_dict(), 'model_with_natural_images.pth')\n",
    "print(\"Model dosyası kaydedildi: model_with_natural_images.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T13:12:28.281943Z",
     "iopub.status.busy": "2025-12-17T13:12:28.281626Z",
     "iopub.status.idle": "2025-12-17T13:15:25.014855Z",
     "shell.execute_reply": "2025-12-17T13:15:25.013916Z",
     "shell.execute_reply.started": "2025-12-17T13:12:28.281906Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Değerlendirme ve Raporlama\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import random\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(loss_history, label='Eğitim Hatası (Training Loss)')\n",
    "plt.title('Modelin Öğrenme Grafiği')\n",
    "plt.xlabel('Epoch Sayısı')\n",
    "plt.ylabel('Hata Değeri')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(\"Model test ediliyor, lütfen bekleyin...\")\n",
    "tum_tahminler = []\n",
    "tum_gercekler = []\n",
    "\n",
    "model.eval() \n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        tum_tahminler.extend(preds.cpu().numpy())\n",
    "        tum_gercekler.extend(labels.numpy())\n",
    "\n",
    "try:\n",
    "    target_names = bitki_siniflari\n",
    "except:\n",
    "    target_names = full_dataset.classes\n",
    "\n",
    "print(\"\\n--- DETAYLI SINIFLANDIRMA RAPORU ---\")\n",
    "print(classification_report(tum_gercekler, tum_tahminler, target_names=target_names))\n",
    "\n",
    "cm = confusion_matrix(tum_gercekler, tum_tahminler)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=target_names, \n",
    "            yticklabels=target_names)\n",
    "plt.xlabel('Modelin Tahmini')\n",
    "plt.ylabel('Gerçek Durum')\n",
    "plt.title('Confusion Matrix (Hata Haritası)')\n",
    "plt.xticks(rotation=90) \n",
    "plt.show()\n",
    "\n",
    "# SINIF DAĞILIMI GRAFİĞİ (Bar Chart)\n",
    "print(\"Veri seti dağılımı hesaplanıyor (Biraz sürebilir)...\")\n",
    "\n",
    "# DataLoader'dan gerçek sayıları al\n",
    "label_counts = torch.zeros(len(bitki_siniflari))\n",
    "with torch.no_grad():\n",
    "    for _, targets in train_loader:\n",
    "        for target in targets:\n",
    "            label_counts[target] += 1\n",
    "\n",
    "counts_np = label_counts.numpy().astype(int)\n",
    "\n",
    "# Grafiği Çiz\n",
    "plt.figure(figsize=(14, 6))\n",
    "ax = sns.barplot(x=bitki_siniflari, y=counts_np, palette=\"viridis\")\n",
    "\n",
    "# Sayıları çubukların üstüne yaz\n",
    "for i, v in enumerate(counts_np):\n",
    "    ax.text(i, v + 5, str(v), color='black', fontweight='bold', ha='center', fontsize=9)\n",
    "\n",
    "plt.title('Eğitim Veri Seti Sınıf Dağılımı (Bitkiler + Others)', fontsize=15)\n",
    "plt.ylabel('Fotoğraf Sayısı')\n",
    "plt.xticks(rotation=90) # İsimler sığsın \n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ÖRNEK FOTOĞRAFLAR (Bitkiler + Others)\n",
    "# Göstermek istediğimiz bitkiler\n",
    "visual_targets = [\"Tomato\", \"Apple\", \"Grape\", \"Corn\"]\n",
    "\n",
    "# Tablo boyutunu ayarla\n",
    "fig, axes = plt.subplots(len(visual_targets) + 1, 2, figsize=(10, 18))\n",
    "fig.suptitle('Veri Setinden Rastgele Örnekler', fontsize=16)\n",
    "\n",
    "# A) BİTKİLERİ GÖSTER (Sağlıklı vs Hasta)\n",
    "for i, plant in enumerate(visual_targets):\n",
    "    # Klasör desenleri\n",
    "    healthy_pattern = os.path.join(train_dir, f\"{plant}*healthy*\")\n",
    "    disease_pattern = os.path.join(train_dir, f\"{plant}*\")\n",
    "    \n",
    "    # Klasörleri bul\n",
    "    healthy_folders = glob.glob(healthy_pattern)\n",
    "    all_folders = glob.glob(disease_pattern)\n",
    "    disease_folders = [f for f in all_folders if \"healthy\" not in f]\n",
    "    \n",
    "    # 1. Sağlıklı Resim (Sol Sütun)\n",
    "    if healthy_folders:\n",
    "        # Klasörün içindeki jpg'leri bul\n",
    "        img_files = glob.glob(os.path.join(healthy_folders[0], \"*\"))\n",
    "        if img_files:\n",
    "            img = Image.open(random.choice(img_files))\n",
    "            axes[i, 0].imshow(img)\n",
    "            axes[i, 0].set_title(f\"{plant} - Sağlıklı\")\n",
    "    axes[i, 0].axis('off')\n",
    "\n",
    "    # 2. Hastalıklı Resim (Sağ Sütun)\n",
    "    if disease_folders:\n",
    "        random_disease_folder = random.choice(disease_folders)\n",
    "        disease_name = os.path.basename(random_disease_folder).split(\"___\")[-1].replace(\"_\", \" \")\n",
    "        \n",
    "        img_files = glob.glob(os.path.join(random_disease_folder, \"*\"))\n",
    "        if img_files:\n",
    "            img = Image.open(random.choice(img_files))\n",
    "            axes[i, 1].imshow(img)\n",
    "            axes[i, 1].set_title(f\"{plant} - {disease_name}\")\n",
    "    axes[i, 1].axis('off')\n",
    "\n",
    "# B) OTHERS (Natural Images) \n",
    "row_idx = len(visual_targets)\n",
    "\n",
    "# Natural Images klasöründen rastgele iki sınıf seç\n",
    "if os.path.exists(natural_img_path):\n",
    "    others_categories = os.listdir(natural_img_path) \n",
    "    \n",
    "    # Sol Sütun (Rastgele Others 1)\n",
    "    cat1 = random.choice(others_categories)\n",
    "    img_files1 = glob.glob(os.path.join(natural_img_path, cat1, \"*\"))\n",
    "    if img_files1:\n",
    "        img = Image.open(random.choice(img_files1))\n",
    "        axes[row_idx, 0].imshow(img)\n",
    "        axes[row_idx, 0].set_title(f\"Others (Örn: {cat1})\")\n",
    "    \n",
    "    # Sağ Sütun (Rastgele Others 2)\n",
    "    cat2 = random.choice(others_categories)\n",
    "    img_files2 = glob.glob(os.path.join(natural_img_path, cat2, \"*\"))\n",
    "    if img_files2:\n",
    "        img = Image.open(random.choice(img_files2))\n",
    "        axes[row_idx, 1].imshow(img)\n",
    "        axes[row_idx, 1].set_title(f\"Others (Örn: {cat2})\")\n",
    "\n",
    "axes[row_idx, 0].axis('off')\n",
    "axes[row_idx, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.93)\n",
    "plt.show()\n",
    "\n",
    "# RAPORDA KULLANILMADI (çok fazla veri olduğu için yüzdelik sayıların okunması zor)\n",
    "# Mevcut 'cm' (Confusion Matrix) değişkenini kullanır.\n",
    "# Köşegen elemanları (doğru tahminler) / Toplam satır sayısı (gerçek adet)\n",
    "class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "# Renk paleti\n",
    "colors = sns.color_palette(\"husl\", len(bitki_siniflari))\n",
    "bars = plt.bar(bitki_siniflari, class_accuracy, color=colors)\n",
    "\n",
    "plt.title('Sınıf Bazlı Doğruluk Oranları (Per-Class Accuracy)', fontsize=15)\n",
    "plt.ylabel('Başarı Oranı (0.0 - 1.0)', fontsize=12)\n",
    "plt.xlabel('Sınıflar', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0, 1.1) \n",
    "\n",
    "# Çubukların üzerine yüzdeleri yaz\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "             f'%{height*100:.1f}',\n",
    "             ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Matrisi yüzdelik hale getir (Her satırı kendi toplamına böl)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.1%', cmap='Blues', vmin=0, vmax=1,\n",
    "            xticklabels=bitki_siniflari, \n",
    "            yticklabels=bitki_siniflari)\n",
    "plt.xlabel('Modelin Tahmini', fontsize=12)\n",
    "plt.ylabel('Gerçek Durum', fontsize=12)\n",
    "plt.title('Normalize Edilmiş Confusion Matrix (Yüzdelik Başarı)', fontsize=15)\n",
    "plt.xticks(rotation=90) \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 42780,
     "sourceId": 75676,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 78313,
     "sourceId": 182633,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
